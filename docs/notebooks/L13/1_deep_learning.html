

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Neural Networks &mdash; Introduction to Computer-based Physical Modeling 1 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/theme_overrides.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}}, "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Neural Network with Keras" href="2_deep_learning_keras.html" />
    <link rel="prev" title="Lecture Contents" href="../../lectures/L13/overview_13.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> Introduction to Computer-based Physical Modeling
          

          
            
            <img src="../../_static/mona_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Course Information:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/website.html">This Website</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/schedule.html">Course Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/assignments.html">Assignments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/exam.html">Exams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/resources.html">Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#molecular-nanophotonics-group">Molecular Nanophotonics Group</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#python-documentation">Python Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#python-tutorials">Python Tutorials</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/instructor.html">Instructor</a></li>
</ul>
<p class="caption"><span class="caption-text">Jupyter Notebooks:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/Intro/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/Introduction2Jupyter.html">Introduction to Jupyter</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#What-is-Jupyter-Notebook?">What is Jupyter Notebook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Notebook-editor">Notebook editor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Kernels">Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Notebook-documents">Notebook documents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/NotebookEditor.html">Notebook editor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Edit-mode">Edit mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Command-mode">Command mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Keyboard-navigation">Keyboard navigation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Running-code">Running code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Managing-the-kernel">Managing the kernel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/EditCells.html">Entering code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/EditCells.html#Entering-Markdown">Entering Markdown</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Markdown-basics">Markdown basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Headings">Headings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Embedded-code">Embedded code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#LaTeX-equations">LaTeX equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Images">Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Videos">Videos</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L1/overview_1.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L1/1_variables.html">Variables and types</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Symbol-names">Symbol names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Variable-Assignment">Variable Assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Number-types">Number types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Integers">Integers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Floating-Point">Floating Point</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Complex-Numbers">Complex Numbers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Type-casting">Type casting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L1/2_operators.html">Operators and comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L1/3_datatypes.html">Data Types in Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Strings">Strings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Lists">Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Tuples">Tuples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Dictionaries">Dictionaries</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L1/4_modules.html">Modules and namespaces</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Modules">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Namespaces">Namespaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Contents-of-a-module">Contents of a module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L1/assignment_1.html">Exercise 1</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L2/overview_2.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L2/1_numpy.html">NumPy arrays</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Creating-Numpy-Arrays">Creating Numpy Arrays</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#From-lists">From lists</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Using-array-generating-functions">Using array-generating functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#linspace-and-logspace">linspace and logspace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#mgrid">mgrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#diag">diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#zeros-and-ones">zeros and ones</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Manipulating-NumPy-arrays">Manipulating NumPy arrays</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Slicing">Slicing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Reshaping">Reshaping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Adding-a-new-dimension:-newaxis">Adding a new dimension: newaxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Stacking-and-repeating-arrays">Stacking and repeating arrays</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Tile-and-repeat">Tile and repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Concatenate">Concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Hstack-and-vstack">Hstack and vstack</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Applying-mathematical-functions">Applying mathematical functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Operation-involving-one-array">Operation involving one array</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Operations-involving-multiple-arrays">Operations involving multiple arrays</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L2/2_plotting.html">Plotting data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Simple-Plotting">Simple Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Line-Plot">Line Plot</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/2_plotting.html#Axis-Labels">Axis Labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/2_plotting.html#Legends">Legends</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Scatter-plot">Scatter plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Histograms">Histograms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Combined-plots">Combined plots</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Saving-figures">Saving figures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Plots-with-error-bars">Plots with error bars</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Setting-plotting-limits-and-excluding-data">Setting plotting limits and excluding data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/2_plotting.html#Masked-arrays">Masked arrays</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Logarithmic-plots">Logarithmic plots</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Semi-log-plots">Semi-log plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Log-log-plots">Log-log plots</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Arranging-multiple-plots">Arranging multiple plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Contour-and-Density-Plots">Contour and Density Plots</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Simple-contour-plot">Simple contour plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Color-contour-plot">Color contour plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Image-plot">Image plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#3D-Plotting">3D Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Projection-Scence">Projection Scence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Line-Plotting-in-3D">Line Plotting in 3D</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Surface-Plotting">Surface Plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Additional-Plotting">Additional Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Insets">Insets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Spine-axis">Spine axis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/2_plotting.html#Polar-plot">Polar plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/2_plotting.html#Text-annotation">Text annotation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L2/3_randomnumbers.html">Random numbers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Uniformly-distributed-random-numbers">Uniformly distributed random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Normally-distributed-random-numbers">Normally distributed random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Exponentially-distributed-numbers">Exponentially distributed numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Random-distribution-of-integers">Random distribution of integers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L2/assignment_2.html">Exercise 2</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 3:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L3/overview_3.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L3/1_input_output.html">Input and output</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#Keyboard-input">Keyboard input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#Screen-output">Screen output</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#File-input/output">File input/output</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/1_input_output.html#File-I/O-with-NumPy">File I/O with NumPy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Reading-data-from-a-text-file">Reading data from a text file</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Writing-data-to-a-text-file">Writing data to a text file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../L3/1_input_output.html#File-I/O-with-Pandas">File I/O with Pandas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Short-intro-to-Pandas">Short intro to Pandas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Reading-CSV-data-with-Pandas">Reading CSV data with Pandas</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/2_flowcontrol.html">Flow Control</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/2_flowcontrol.html#Conditionals:-if,-elif,-and-else-statements">Conditionals: if, elif, and else statements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If-example">If example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If-else-example">If else example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If,-elif,-else-example">If, elif, else example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#Combining-conditions">Combining conditions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L3/2_flowcontrol.html#Loops">Loops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#For-loops">For loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#While-loops">While loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#Loops-and-array-operations">Loops and array operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#List-comprehensions">List comprehensions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/3_functions.html">Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Function-definition">Function definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Variables-in-functions">Variables in functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Functions-with-more-than-one-input-or-output">Functions with more than one input or output</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/3_functions.html#Positional-and-keyword-arguments">Positional and keyword arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/3_functions.html#Functions-with-variable-number-of-arguments">Functions with variable number of arguments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Unnamed-functions-(lambda-function)">Unnamed functions (lambda function)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Functions-as-arguments-of-functions">Functions as arguments of functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/4_exceptions.html">Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L3/assignment_3.html">Exercise 3</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 4:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L4/overview_4.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L4/1_classes.html">Classes and Objects</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Definition-of-Classes">Definition of Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Class-Methods">Class Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L4/1_classes.html#The-__init__-method">The <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L4/1_classes.html#The-__str__-method">The <code class="docutils literal notranslate"><span class="pre">__str__</span></code> method</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Class-and-object-variables">Class and object variables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L4/2_brownian_motion.html">Brownian Motion</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Physics">Physics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Class-Planning">Class Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Simulating">Simulating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Plotting-the-trajectories">Plotting the trajectories</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Characterizing-the-Brownian-motion">Characterizing the Brownian motion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L4/2_brownian_motion.html#Calculate-the-particle-velocity">Calculate the particle velocity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L4/2_brownian_motion.html#Calculate-the-particle-mean-squared-displacement">Calculate the particle mean squared displacement</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L4/3_animations.html">Animations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Import-Modules">Import Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Particle-class">Particle class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Create-a-set-of-particles">Create a set of particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Canvas-and-drawing-function">Canvas and drawing function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Threading-for-animation">Threading for animation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L4/assignment_4.html">Exercise 4</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 5:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L5/overview_5.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L5/1_differentiation.html">Numerical Differentiation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#First-order-derivative">First order derivative</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/1_differentiation.html#Matrix-version-of-the-first-derivative">Matrix version of the first derivative</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#Second-order-derivative">Second order derivative</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#SciPy-Module">SciPy Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/1_differentiation.html#Matrix-version">Matrix version</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L5/2_integration.html">Numerical Integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Box-method">Box method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Trapezoid-method">Trapezoid method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Simpson-method">Simpson method</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L5/3_solving_ODEs.html">Solving ODEs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Harmonic-Oscillator">Harmonic Oscillator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Implicit-Solution---Crank-Nicholson">Implicit Solution - Crank Nicholson</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Define-Matrices">Define Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Use-Initial-Conditions">Use Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solution">Solution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Explicit-Solution---Numerical-Integration">Explicit Solution - Numerical Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Euler-Method">Euler Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Euler-Cromer-Method">Euler Cromer Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Midpoint-Method">Midpoint Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Putting-it-all-together">Putting it all together</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L5/3_solving_ODEs.html#The-definition-of-the-problem">The definition of the problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solving-the-problem">Solving the problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solving-the-Harmonic-Oscillator-in-SciPy">Solving the Harmonic Oscillator in SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Definition">Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id1">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Plotting">Plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Damped-Driven-Pendulum-in-SciPy">Damped Driven Pendulum in SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id2">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id3">Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id4">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id5">Plotting</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 6:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L6/overview_6.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L6/1_covid19.html">COVID19</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#The-Kermack-McKendrick-Model">The Kermack-McKendrick Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Model-Equation">Model Equation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Definition">Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Solution">Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Plotting">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Real-COVID19-numbers">Real COVID19 numbers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Total-number-of-cases">Total number of cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Number-of-Deaths">Number of Deaths</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#New-cases-per-day">New cases per day</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Current-cases">Current cases</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L6/2_coupled_pendula.html">Coupled Pendula</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Description-of-the-problem">Description of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Sketch">Sketch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Equations-of-motion">Equations of motion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Solving-the-problem">Solving the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Setting-up-the-function">Setting up the function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Define-initial-parameters">Define initial parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Solve-the-equation-of-motion">Solve the equation of motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Animation">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Normal-Modes">Normal Modes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#In-phase-motion">In-phase motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Out-of-phase-motion">Out-of-phase motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Beat-case">Beat case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Computation-of-energy-(here-for-the-beat-case)">Computation of energy (here for the beat case)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Potential-energy-of-the-pendula">Potential energy of the pendula</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Potential-energy-of-the-spring">Potential energy of the spring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Kinetic-energies">Kinetic energies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Total-energy">Total energy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Total-energy-exchange-of-the-pendula">Total energy exchange of the pendula</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L6/3_fourier_analysis.html">Fourier Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Fourier-series">Fourier series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Fourier-transform">Fourier transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Frequency-analysis-of-our-coupled-pendula">Frequency analysis of our coupled pendula</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 7:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L7/overview_7.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L7/1_spring_pendulum.html">Spring Pendulum</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/1_spring_pendulum.html#Physical-Model">Physical Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Equations-of-motion">Equations of motion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L7/1_spring_pendulum.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Initial-parameters">Initial parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Plotting">Plotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L7/1_spring_pendulum.html#Angle-and-Length-over-Time">Angle and Length over Time</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L7/2_planetary_motion.html">Planetary Motion</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/2_planetary_motion.html#Physical-Model">Physical Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L7/2_planetary_motion.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Initial-Parameters:-Planets">Initial Parameters: Planets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Solution:-Planets">Solution: Planets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Plotting:-Planets">Plotting: Planets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L7/2_planetary_motion.html#Trajectory">Trajectory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L7/2_planetary_motion.html#Energy">Energy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L7/3_diffusion_equation.html">Diffusion equation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/3_diffusion_equation.html#Physical-Model">Physical Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Spatial-derivative">Spatial derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Temporal-derivative">Temporal derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Bringing-all-together">Bringing all together</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L7/3_diffusion_equation.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Setup-Domain">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Matrix-Setup">Matrix Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Solution">Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L7/assignment_7.html">Exercise 7</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 8:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L8/overview_8.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L8/1_curve_fitting.html">Curve fitting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Idea">Idea</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Least-squares">Least squares</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Least-square-fitting">Least square fitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L8/1_curve_fitting.html#\chi-squared-value"><span class="math notranslate nohighlight">\(\chi\)</span>-squared value</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L8/1_curve_fitting.html#Residuals">Residuals</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Covariance-matrix">Covariance matrix</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 9:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L9/overview_9.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L9/1_plane_waves.html">Plane Waves</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Equations">Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Electric-field">Electric field</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Plane-wave-propagation">Plane wave propagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Imaginary-wave-vector">Imaginary wave vector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Interference-of-two-plane-waves">Interference of two plane waves</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L9/1_plane_waves.html#Plane-wave-at-a-boundary">Plane wave at a boundary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Fresnel-equations">Fresnel equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Incident-wave">Incident wave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Reflected-wave">Reflected wave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/1_plane_waves.html#Refracted-wave">Refracted wave</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L9/2_spherical_waves.html">Spherical waves</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Equations">Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Electric-field">Electric field</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Plot-the-intensity-in-an-image-plane">Plot the intensity in an image plane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Interference-between-a-spherical-and-a-plane-wave">Interference between a spherical and a plane wave</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L9/3_huygens_principle.html">Huygens principle</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Diffraction-pattern-of-a-single-slit">Diffraction pattern of a single slit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Farfield-vs. nearfield">Farfield vs. nearfield</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Comparison-to-the-analytical-solution">Comparison to the analytical solution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L9/4_gaussian_beams.html">Gaussian Beam</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Equations">Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Intensity-plot">Intensity plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Intensity-profiles">Intensity profiles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L9/assignment_9.html">Exercise 9</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 10:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L10/overview_10.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L10/1_quantum_mechanics.html">Quantum Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Quantum-Mechanics-in-a-Nutshell">Quantum Mechanics in a Nutshell</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Time-dependent-Schrödinger-equation">Time dependent Schrödinger equation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Stationary-Schrödinger-equation">Stationary Schrödinger equation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Recap:-Implicit-Solution">Recap: Implicit Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Potential-energy">Potential energy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/2_particle_in_a_box.html">Particle in a box</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Energies-of-bound-states">Energies of bound states</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/3_harmonic_oscillator.html">Harmonic Oscillator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Energies-of-the-states">Energies of the states</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/4_periodic_potential.html">Periodic Potential</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Plotting">Plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Energy-states">Energy states</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 11:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L11/overview_11.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L11/1_quantum_dynamics.html">Time Dependent Quantum Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Time-dependent-Schrödinger-equation">Time dependent Schrödinger equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepackets">Wavepackets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Demonstration-of-superposition-of-plane-waves">Demonstration of superposition of plane waves</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepacket">Wavepacket</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepacket-with-rectangular-amplitude">Wavepacket with rectangular amplitude</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Gaussian-Wave-Packet">Gaussian Wave Packet</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Time-evolution-of-a-Gaussian-Wavepacket">Time evolution of a Gaussian Wavepacket</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L11/2_particle_in_a_box.html">Wavepacket in a Potential Box</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Problem-Setup">Problem Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Initial-conditions">Initial conditions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Eigenfunctions">Eigenfunctions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Quality-of-the-coefficients">Quality of the coefficients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L11/3_tunneling.html">Tunneling through a barrier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Schrödinger-equation-for-the-momentum">Schrödinger equation for the momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Crank-Nicolson-Solution">Crank Nicolson Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Setup-Domain">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Matrix-Setup">Matrix Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Propagation-Matrix">Propagation Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Animation-setup">Animation setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Animation">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Split-Step-Method">Split Step Method</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id1">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Potential-energy-landscape">Potential energy landscape</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Initial-wavepacket">Initial wavepacket</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Fourier-Transform-Setup">Fourier Transform Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Phase-Factor-per-Timestep">Phase Factor per Timestep</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id2">Animation setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id3">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 12:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L12/overview_12.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L12/1_hydrodynamics.html">Hydrodynamics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Falling-sphere">Falling sphere</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Function-definition">Function definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Numerical-solution">Numerical solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Analytical-solution">Analytical solution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Stokes-equation">Stokes equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Fundamental-Solutions-of-the-Stokes-Equation">Fundamental Solutions of the Stokes Equation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Stokeslet">Stokeslet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Source-dipole">Source dipole</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Sum-of-both-solutions">Sum of both solutions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L12/2_reinforcement_learning.html">Machine Learning and Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Reinforcement-Learning">Reinforcement Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Markov-Decision-Process">Markov Decision Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Methods-or-RL">Methods or RL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Navigating-a-Grid-World">Navigating a Grid World</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Initialize-Reinforcement-Learning">Initialize Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#List-of-actions">List of actions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Initial-state">Initial state</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Reinforcement-Learning-Loop">Reinforcement Learning Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Convergence-of-the-Q-learning">Convergence of the Q-learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Policy">Policy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Plot-the-policy">Plot the policy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Where-to-go-from-here">Where to go from here</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 13:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L13/overview_13.html">Lecture Contents</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#The-MNIST-Data-Set">The MNIST Data Set</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Normalize-the-data">Normalize the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Preparing-training-and-testing-data">Preparing training and testing data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#A-Single-Neuron">A Single Neuron</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Forward-Propogation">Forward Propogation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Loss-Function">Loss Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Trainging-the-Network">Trainging the Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Backward-Propagation">Backward Propagation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Stochastic-Gradient-Descent">Stochastic Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Build-an-Train">Build an Train</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Testing-our-model">Testing our model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Network-with-Hidden-Layers">Network with Hidden Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Multiclass-Network">Multiclass Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Changes-to-the-model">Changes to the model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Forward-Pass">Forward Pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Loss Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Back-Propagation">Back Propagation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Build-and-Train">Build and Train</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Model-performance">Model performance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Test-the-model">Test the model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="2_deep_learning_keras.html">Neural Network with Keras</a><ul>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#MNIST-Data-Set-(Keras)">MNIST Data Set (Keras)</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Build-the-model">Build the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Compile-the-model">Compile the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Train-the-model">Train the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Testing-the-model">Testing the model</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 14:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L14/overview_14.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L14/1_CNN.html">Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Layout-of-a-CNN">Layout of a CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Convolutional-Layer">Convolutional Layer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L14/1_CNN.html#Padding">Padding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L14/1_CNN.html#Striding">Striding</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#RELU-Activation">RELU Activation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Pooling-Layer">Pooling Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Output-Size">Output Size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Flattening">Flattening</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Dropout">Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Fully-Connected-Layer">Fully Connected Layer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L14/1_CNN.html#Example-CNN-with-Keras">Example CNN with Keras</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Prepare-the-data">Prepare the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Build-the-network">Build the network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Train-the-network">Train the network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Evaluate-the-trained-network">Evaluate the trained network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Evaluate-the-accuracy-of-your-visual-neural-network-;-)">Evaluate the accuracy of your visual neural network ;-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/1_CNN.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L14/2_AutoEncoder.html">Autoencoder CNN for Time Series Denoising</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L14/2_AutoEncoder.html#Autoencoder-Structure-and-Purpose">Autoencoder Structure and Purpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/2_AutoEncoder.html#Data-Generation">Data Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L14/2_AutoEncoder.html#Create-the-Autoencoder-network">Create the Autoencoder network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L14/2_AutoEncoder.html#Define-model-data">Define model data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L14/2_AutoEncoder.html#Encoder/Decoder-Setup">Encoder/Decoder Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L14/2_AutoEncoder.html#Training-the-encoder">Training the encoder</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L14/2_AutoEncoder.html#Reconstruction-of-the-Data">Reconstruction of the Data</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 15:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L15/overview_15.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L15/1_python_hardware.html">Python and Hardware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L15/1_python_hardware.html#Arduino-Nano-Board">Arduino Nano Board</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L15/1_python_hardware.html#Arduino-Software">Arduino Software</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L15/1_python_hardware.html#Setup-your-board">Setup your board</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L15/1_python_hardware.html#Select-Firmata-Sketch">Select Firmata Sketch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L15/1_python_hardware.html#Communicating-with-the-board">Communicating with the board</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L15/1_python_hardware.html#Let-the-on-board-LED-blink">Let the on-board LED blink</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L15/1_python_hardware.html#Tunable-output">Tunable output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L15/1_python_hardware.html#Creating-an-Oscilloscope">Creating an Oscilloscope</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L15/2_project_template.html">Project: YOUR PROJECT TITLE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L15/2_project_template.html#Introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L15/2_project_template.html#Fundamentals">Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L15/2_project_template.html#Results-and-Discussion">Results and Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L15/2_project_template.html#Summary">Summary</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Introduction to Computer-based Physical Modeling</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Neural Networks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/fcichos/website/blob/master//source/notebooks/L13/1_deep_learning.ipynb" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="admonition note">
<p>This page was generated from <a href="#id2"><span class="problematic" id="id3">`source/notebooks/L13/1_deep_learning.ipynb`_</span></a>.
<span class="raw-html"><br/><a href="https://mybinder.org/v2/gh/fcichos/website/master?urlpath=tree/source/notebooks/L13/1_deep_learning.ipynb"><img alt="Binder badge" src="https://img.shields.io/badge/launch-full%20binder-red.svg" style="vertical-align:text-bottom"></a></span></p>
</div>
<div class="section" id="Neural-Networks">
<h1>Neural Networks<a class="headerlink" href="#Neural-Networks" title="Permalink to this headline">¶</a></h1>
<p>Neural networks are one of the most commonly used machine learning objects nowadays. Mostly these systems are known as <strong>deep neural networks</strong>, which just says something about how many layers in which neurons are arranged exist. We will in this lecture have a look at the basic unit, the neuron, and how to connect and train a network. We will do all ourselves, that means, we will not use one of the many existing python modules, that simplifies the task. This notebook has been largely developed
by <strong>Martin Fränzl</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[238]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;


<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                     <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                     <span class="s1">&#39;axes.labelpad&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.labelsize&#39;</span> <span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.labelsize&#39;</span> <span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.top&#39;</span> <span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.direction&#39;</span> <span class="p">:</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.right&#39;</span> <span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.direction&#39;</span> <span class="p">:</span> <span class="s1">&#39;in&#39;</span>
                    <span class="p">})</span>
</pre></div>
</div>
</div>
<p>In this lecture we are going to build a neural network from scratch using Python and NumPy (The high-level libaries like Keras and TensorFlow will be covered in Part 2). We will build a network to recognize hand-written digits, using the famous MNIST data set.</p>
<p><img alt="MNIS" src="../../_images/MNIST.png" /></p>
<p>We will start with the simplest possible “network”: A single node that recognizes just the digit 0. This is actually just an implementation of logistic regression, but it will help us understand some of the key components before things get more complicated. Then we’ll extend that into a network with one hidden layer, still recognizing just 0. Finally, we will extend the network to recognize all the digits 0 through 9. That will give us a 92% accurate digit-recognizer.</p>
<div class="section" id="The-MNIST-Data-Set">
<h2>The MNIST Data Set<a class="headerlink" href="#The-MNIST-Data-Set" title="Permalink to this headline">¶</a></h2>
<p>The MNIST data set contains 70,000 images of hand-written digits, each 28 x 28 pixels, in greyscale with pixel-values from 0 to 255. We could download and preprocess the data ourselves, but the makers of the module <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> already did that for us:</p>
<div class="section" id="Load-the-data">
<h3>Load the data<a class="headerlink" href="#Load-the-data" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[271]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The images are now contained in the array <code class="docutils literal notranslate"><span class="pre">X</span></code>, while the labels (so which number it is) are contained in <code class="docutils literal notranslate"><span class="pre">y</span></code>. Let’s have a look at a random image and label.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[241]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;label: &#39;</span><span class="p">,</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_10_0.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_10_0.png" style="width: 323px; height: 255px;" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
label:  4
</pre></div></div>
</div>
</div>
<div class="section" id="Normalize-the-data">
<h3>Normalize the data<a class="headerlink" href="#Normalize-the-data" title="Permalink to this headline">¶</a></h3>
<p>To use data in neural networks as training data, it is always useful to normalize the data to the interval [0, 1].</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[242]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="mi">255</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Preparing-training-and-testing-data">
<h3>Preparing training and testing data<a class="headerlink" href="#Preparing-training-and-testing-data" title="Permalink to this headline">¶</a></h3>
<p>The default MNIST labels say ‘1’ for an image of a one, ‘2’ for an image of a two, etc., but we are just building a zero classifier for now. So we want our labels to say 1 when we have a zero, and 0 otherwise. So we overwrite the labels accordingly:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[243]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y_new</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="s1">&#39;0&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y_new</span>
</pre></div>
</div>
</div>
<p>We now split the data in a train and test set. The MNIST images are pre-arranged so that the first 60,000 can be used for training, and the last 10,000 for testing. We’ll also transform the data into the shape we want, with each example in a column (instead of a row):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[244]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">m</span> <span class="o">=</span> <span class="mi">60000</span>
<span class="n">m_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">m</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="n">m</span><span class="p">:]</span><span class="o">.</span><span class="n">T</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">m</span><span class="p">),</span> <span class="n">y</span><span class="p">[</span><span class="n">m</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Finally, we shuffle the training set:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[245]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shuffle_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span><span class="n">shuffle_index</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:,</span><span class="n">shuffle_index</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Let’s again have a look at random image and label just to check</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[270]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_22_0.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_22_0.png" style="width: 317px; height: 259px;" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0.]
</pre></div></div>
</div>
<p>Try to find a zero to check whether the corresponding label is a 1.</p>
</div>
</div>
<div class="section" id="A-Single-Neuron">
<h2>A Single Neuron<a class="headerlink" href="#A-Single-Neuron" title="Permalink to this headline">¶</a></h2>
<p>The basic unit of a neural network is a neuron. A neuron takes inputs, does some math with them, and produces one output. The neuron below does that with two inputs.</p>
<p><img alt="image" src="../../_images/neuron.png" /></p>
<div class="section" id="Forward-Propogation">
<h3>Forward Propogation<a class="headerlink" href="#Forward-Propogation" title="Permalink to this headline">¶</a></h3>
<p>The neuron does now three things.</p>
<ol class="arabic simple">
<li><p>Take input values and multipy by weights</p></li>
</ol>
<p><span class="math">\begin{eqnarray}
x_{1}\rightarrow x_{1} w_{1}\\
x_{2}\rightarrow x_{2} w_{2}
\end{eqnarray}</span></p>
<ol class="arabic simple" start="2">
<li><p>All the weighted inputs are the added to a bias value <span class="math notranslate nohighlight">\(b\)</span></p></li>
</ol>
<p><span class="math">\begin{equation}
x_{1} w_{1}+ x_{2} w_{2}+b
\end{equation}</span></p>
<ol class="arabic simple" start="3">
<li><p>The output is generated by applying a function <span class="math notranslate nohighlight">\(\sigma()\)</span> <span class="math">\begin{equation}
y=\sigma( x_{1} w_{1}+ x_{2} w_{2}+b)
\end{equation}</span></p></li>
</ol>
<p>This function is called activation function. The activation function is used to turn an unbounded input value into a bounded output value with a predictable range. A commonly used activation function is the <code class="docutils literal notranslate"><span class="pre">sigmoid</span> <span class="pre">function</span></code>.</p>
<p>For a single input dataset <span class="math notranslate nohighlight">\(x\)</span> a more compact writing of the math above is</p>
<p><span class="math">\begin{equation*}
\hat{y} = \sigma(w^{\rm T} x + b)\ .
\end{equation*}</span></p>
<p>Here <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function: <span class="math">\begin{equation*}
\sigma(z) = \frac{1}{1+{\rm e}^{-z}}\ .
\end{equation*}</span></p>
<p>The sigmoid function is something we can already define and plot.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[272]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="sa">u</span><span class="s2">&quot;</span><span class="se">\u2212</span><span class="s2">&quot;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[272]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;−&#39;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[66]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[67]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_32_0.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_32_0.png" style="width: 348px; height: 219px;" />
</div>
</div>
<p>If we now have this kind of two input neuron with the weights <span class="math notranslate nohighlight">\(w\)</span> and the bias value <span class="math notranslate nohighlight">\(b\)</span></p>
<p><span class="math">\begin{eqnarray}
w=[0,1]\\
b=4
\end{eqnarray}</span></p>
<p>we may supply and input</p>
<p><span class="math">\begin{eqnarray}
x=[2,3]
\end{eqnarray}</span></p>
<p>which gives writing it a s a dot product</p>
<p><span class="math">\begin{equation}
y=f(w\cdot x+b)=f(7)=0.999
\end{equation}</span></p>
<p>This procedure of propagating the input values to obtain and output value is called <strong>feedforward</strong> or <strong>forward propagation</strong>. Our first goal is now to create a network with a single neuron with 784 inputs (28 x 28), and a single sigmoid unit generating the output.</p>
<p>The above examples can be written and executed more efficiently in a vectorized form. Generating the output We’ll vectorize by stacking examples side-by-side, so that our input matrix <span class="math notranslate nohighlight">\(X\)</span> has an example in each column. The vectorized form of the forward pass is then</p>
<p><span class="math">\begin{equation*}
\hat{y} = \sigma(w^{\rm T} X + b)\ .
\end{equation*}</span></p>
<p>Note that <span class="math notranslate nohighlight">\(\hat{y}\)</span> is now a vector, not a scalar as it was in the previous equation.</p>
<p>In our code we will compute this in two stages: <code class="docutils literal notranslate"><span class="pre">Z</span> <span class="pre">=</span> <span class="pre">np.matmul(W.T,</span> <span class="pre">X)</span> <span class="pre">+</span> <span class="pre">b</span></code> and then <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">sigmoid(Z)</span></code> (<code class="docutils literal notranslate"><span class="pre">A</span></code> for Activation). Breaking things up into stages like this is just for clarity - It will make our forward pass computations mirror the steps in our backward propagation computation.</p>
</div>
<div class="section" id="Loss-Function">
<h3>Loss Function<a class="headerlink" href="#Loss-Function" title="Permalink to this headline">¶</a></h3>
<p>Since we have now data and we also know how to propagate (at least in principle) the input through the single neuron here, we also need to define a measure for how far the output deviates from the input. This measure is called <strong>loss</strong>. The many different ways of defining a suitable loss. The <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">squared</span> <span class="pre">error</span></code>, as it appeared already during our fitting lecture, could be a suitable loss function</p>
<p><span class="math">\begin{equation}
MSE(y,\hat{y})=\frac{1}{n}\sum_{i=1}^{n}(y-\hat{y})^2
\end{equation}</span></p>
<p>for a number of <span class="math notranslate nohighlight">\(n\)</span> datasets. Here <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the data that is predicted by the network and <span class="math notranslate nohighlight">\(y\)</span> is the value which represents the so called ground truth, i.e. the data provided by the training set.</p>
<p>We will not use the mean squared error bu the <code class="docutils literal notranslate"><span class="pre">cross-entropy</span></code> for our loss function. The formula for a single training example (one input image) is:</p>
<p><span class="math">\begin{equation*}
L(y,\hat{y}) = -y\log(\hat{y})-(1-y)\log(1-\hat{y})\ .
\end{equation*}</span></p>
<p>This error definition comes from the Shannon entropy definition, which you may look up in the web if you are interested. Averaging over a training set of <span class="math notranslate nohighlight">\(m\)</span> examples we then have:</p>
<p><span class="math">\begin{equation*}
L(Y,\hat{Y}) = -\frac{1}{m}\sum_{i = 0}^{m}y^{(i)}\log(\hat{y}^{(i)})-(1-y^{(i)})\log(1-\hat{y}^{(i)})\ .
\end{equation*}</span></p>
<p>In Python code, this looks like</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[68]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">L</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">),</span> <span class="n">Y</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y_hat</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">))))</span>
    <span class="k">return</span> <span class="n">L</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Trainging-the-Network">
<h2>Trainging the Network<a class="headerlink" href="#Trainging-the-Network" title="Permalink to this headline">¶</a></h2>
<p>The goal of all neural network training procedures is to minimize the loss and we have to find a way to minimize that loss. This is not so much different from our fitting of function values before.</p>
<div class="section" id="Backward-Propagation">
<h3>Backward Propagation<a class="headerlink" href="#Backward-Propagation" title="Permalink to this headline">¶</a></h3>
<p>The output of the network is determined by the input values and how we have distributed the weights <span class="math notranslate nohighlight">\(w\)</span> and the biases <span class="math notranslate nohighlight">\(b\)</span>. We can write the loss function therefore as a function of the weights and losses</p>
<div class="math notranslate nohighlight">
\[L(w_{1},w_{2},w_{3},\ldots ,b_{1},b_{2},b_{3},\ldots)\]</div>
<p>To train the network, we would now try to find out, by how much the output values change if we do change a specific weight <span class="math notranslate nohighlight">\(w_j\)</span>. This can be expressed by the partial derivative</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L}{\partial w_j}\]</div>
<p>We may then take a tiny step and correct the current value of <span class="math notranslate nohighlight">\(w_j\)</span> such that the network yields a new output. This way back from the current output of the network and its current loss to a correction of the weights to yield a smaller loss is called <strong>back propagation</strong>.</p>
<p><strong>Calculating derivatives</strong></p>
<p>Focusing on a single input image will make it easier to derive the formulas we need. Holding all values except <span class="math notranslate nohighlight">\(w_j\)</span> fixed, we can think of <span class="math notranslate nohighlight">\(L\)</span> as being computed in three steps: <span class="math notranslate nohighlight">\(w_j\rightarrow z \rightarrow \hat{y} \rightarrow L\)</span>. The formulas for these steps are: <span class="math">\begin{align*}
z &= w^{\rm T} x + b\ , \\
\hat{y} &= \sigma(z)\ , \\
L(y,\hat{y}) &= -y\log(\hat{y})-(1-y)\log(1-\hat{y})\ .
\end{align*}</span></p>
<p>The change of the loss function with the weights can then be split up by the chain rule into</p>
<p><span class="math">\begin{align*}
\frac{\partial L}{\partial w_j} = \frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial z}\frac{\partial z}{\partial w_j}
\end{align*}</span></p>
<p>There we have a product of three individual partial derivatives, which are a bit tedius to write down, but not to complicated. The read like</p>
<p><span class="math notranslate nohighlight">\(\partial L/\partial\hat{y}\)</span>: <span class="math">\begin{align*}
\frac{\partial L}{\partial\hat{y}} &= \frac{\partial}{\partial\hat{y}}\left(-y\log(\hat{y})-(1-y)\log(1-\hat{y})\right) \\
&= -y\frac{\partial}{\partial\hat{y}}\log(\hat{y})-(1-y)\frac{\partial}{\partial\hat{y}}\log(1-\hat{y}) \\
&= -\frac{y}{\hat{y}} +\frac{(1 - y)}{1-\hat{y}} \\
&= \frac{\hat{y} - y}{\hat{y}(1-\hat{y})}
\end{align*}</span></p>
<p><span class="math notranslate nohighlight">\(\partial \hat{y}/\partial z\)</span>: <span class="math">\begin{align*}
\frac{\partial }{\partial z}\sigma(z)
&= \frac{\partial }{\partial z}\left(\frac{1}{1 + {\rm e}^{-z}}\right) \\
&= \frac{1}{(1 + {\rm e}^{-z})^2}\frac{\partial }{\partial z}(1 + {\rm e}^{-z}) \\
&= \frac{{\rm e}^{-z}}{(1 + {\rm e}^{-z})^2} \\
&= \frac{1}{1 + {\rm e}^{-z}}\frac{{\rm e}^{-z}}{1 + {\rm e}^{-z}} \\
&= \frac{1}{1 + {\rm e}^{-z}}\left(1 - \frac{1}{1 + {\rm e}^{-z}}\right) \\
&= \sigma(z)(1-\sigma(z)) \\
&= \hat{y}(1-\hat{y})
\end{align*}</span></p>
<p><span class="math notranslate nohighlight">\(\partial z/\partial w_j\)</span>: <span class="math">\begin{align*}
\frac{\partial }{\partial w_j}(w^{\rm T} x + b) &= \frac{\partial }{\partial w_j}(w_0x_0 + \dots + w_nx_n + b) \\
&= x_j
\end{align*}</span></p>
<p>Substituting back into the chain rule yields: <span class="math">\begin{align*}
\frac{\partial L}{\partial w_j}
&= \frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial z}\frac{\partial z}{\partial w_j} \\
&= \frac{\hat{y} - y}{\hat{y}(1-\hat{y})}\hat{y}(1-\hat{y}) x_j \\
&= (\hat{y} - y)x_j\ .
\end{align*}</span></p>
<p>which does not look that unfriendly anymore.</p>
<p>In vectorized form with <span class="math notranslate nohighlight">\(m\)</span> training examples this gives us <span class="math">\begin{align*}
\frac{\partial L}{\partial w} = \frac{1}{m} X(\hat{y} - y)^{\rm T}\ .
\end{align*}</span></p>
<p>A very similar derivation of <span class="math notranslate nohighlight">\(\partial L/\partial b\)</span> yields, for a single example: <span class="math">\begin{align*}
\frac{\partial L}{\partial b} = (\hat{y} - y)\ .
\end{align*}</span></p>
<p>In vectorized form we get <span class="math">\begin{align*}
\frac{\partial L}{\partial b} = \frac{1}{m}\sum_{i=1}^{m}{(\hat{y}^{(i)} - y^{(i)})}\ .
\end{align*}</span></p>
<p>In our code we label these gradients according to their denominators, as <code class="docutils literal notranslate"><span class="pre">dW</span></code> and <code class="docutils literal notranslate"><span class="pre">db</span></code>. So for backpropagation we compute <code class="docutils literal notranslate"><span class="pre">dW</span> <span class="pre">=</span> <span class="pre">(1/m)</span> <span class="pre">*</span> <span class="pre">np.matmul(X,</span> <span class="pre">(A-Y).T)</span></code> and <code class="docutils literal notranslate"><span class="pre">db</span> <span class="pre">=</span> <span class="pre">(1/m)*np.sum(A-Y,</span> <span class="pre">axis=1,</span> <span class="pre">keepdims=True)</span></code>.</p>
</div>
<div class="section" id="Stochastic-Gradient-Descent">
<h3>Stochastic Gradient Descent<a class="headerlink" href="#Stochastic-Gradient-Descent" title="Permalink to this headline">¶</a></h3>
<p>We have all the tools we need to train a neural network now! We’ll use an optimization algorithm called stochastic gradient descent (SGD) that tells us how to change our weights and biases to minimize loss. It is a simple umpdate of the weights and biases, which would read for the weights like</p>
<div class="math notranslate nohighlight">
\[w\leftarrow w-\eta\frac{\partial L}{\partial w}\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is a constant called the learning rate that controls how fast we train. All we’re doing is subtracting <span class="math notranslate nohighlight">\(\eta \partial L/\partial w\)</span> from <span class="math notranslate nohighlight">\(w\)</span></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(\partial L/\partial w\)</span> is positive, <span class="math notranslate nohighlight">\(w\)</span> will decrease, which makes L decrease.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\partial L/\partial w\)</span> is negative, <span class="math notranslate nohighlight">\(w\)</span> will increase, which makes L decrease.</p></li>
</ul>
<p>The equations look equivalent for the bias <span class="math notranslate nohighlight">\(b\)</span>. Our back propagation procedure will do that for as many steps we want, i.e. until we feel that the output is close enough to the ground truth. Each back propagation step is called and <code class="docutils literal notranslate"><span class="pre">epoch</span></code>.</p>
</div>
<div class="section" id="Build-an-Train">
<h3>Build an Train<a class="headerlink" href="#Build-an-Train" title="Permalink to this headline">¶</a></h3>
<p>Now we have all things together to create a single neuron network doing the analysis of the MNIST numbers. This type of data processing is called logistic regression based on the sigmoid function, which is a logistic function. So let’s create all in python code and train the network for 100 epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[69]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="n">n_x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

    <span class="n">dW</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot; loss: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 0  loss:  0.7471125121616977
Epoch 10  loss:  0.0730826958292902
Epoch 20  loss:  0.06131832354627721
Epoch 30  loss:  0.055230119812005714
Epoch 40  loss:  0.0513243202361425
Epoch 50  loss:  0.04854004196371184
Epoch 60  loss:  0.04642485272904433
Epoch 70  loss:  0.04474722082574824
Epoch 80  loss:  0.043374333931969114
Epoch 90  loss:  0.042223715518407964
Final loss: 0.04133292114839401
</pre></div></div>
</div>
<p>We do not really now how to judge the quality of our trained network. At least we saw that the loss is decreasing, which is good. We may judge the quality of our trained network by calculating the so-called <strong>confusion matrix</strong>. The confusion matrix is creating a matrix giving reports the actual values in the rows and the predicted values in the columns.</p>
<p><img alt="confusion_matrix" src="../../_images/confusion_matrix.png" /></p>
<p>The entries in the matrix are called <strong>true positives</strong> (TP), <strong>false positives</strong> (FP), <strong>false negatives</strong> (FN), and <strong>true negatives</strong> (TN). Fortunately we can use a method of the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> module to calculate the confusion matrix. We just have to supply the predictions and the actual labels to it. To do so, we use the testing data set <code class="docutils literal notranslate"><span class="pre">X_test</span></code> which we have splitted earlier.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[73]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="o">&gt;.</span><span class="mi">5</span><span class="p">)[</span><span class="mi">0</span><span class="p">,:]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,:]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[8973   42]
 [  47  938]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[92]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
              precision    recall  f1-score   support

       False       0.99      1.00      1.00      9015
        True       0.96      0.95      0.95       985

    accuracy                           0.99     10000
   macro avg       0.98      0.97      0.97     10000
weighted avg       0.99      0.99      0.99     10000

</pre></div></div>
</div>
</div>
<div class="section" id="Testing-our-model">
<h3>Testing our model<a class="headerlink" href="#Testing-our-model" title="Permalink to this headline">¶</a></h3>
<p>We can check a single image of our testing data with the following line. If the output number is bigger than 0.5, our number is likely a 0.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[232]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">i</span><span class="o">=</span><span class="mi">10</span>
<span class="nb">bool</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X_test</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span><span class="o">+</span><span class="n">b</span><span class="p">)</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[232]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
True
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[231]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[231]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.image.AxesImage at 0x7feac155d110&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_62_1.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_62_1.png" style="width: 258px; height: 255px;" />
</div>
</div>
<p>That’s actually pretty good! We predicted the right values for 8972 cases. We missed only 41 of the cases.</p>
</div>
</div>
<div class="section" id="Network-with-Hidden-Layers">
<h2>Network with Hidden Layers<a class="headerlink" href="#Network-with-Hidden-Layers" title="Permalink to this headline">¶</a></h2>
<p>In our example above, we just had an input layer and a single output neuron. More complex neural networks are containing many layers between the input layer and the output layer. These inbetween layers are called hidden layers. Here is a simple example of a neural network with a single hidden layer.</p>
<p><img alt="hidden" src="../../_images/image.png" /></p>
<p>So we have now and input layer with 784 inputs that are connected to 64 units in the hidden layer and 1 neuron in the output layer. We will not go through the derivations of all the formulas for the forward and backward passes this time. The code is a simple extension of what we did before and I hope easy to read.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[117]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="n">n_x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_h</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_h</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_h</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_h</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">A1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">A2</span><span class="p">)</span>

    <span class="n">dZ2</span> <span class="o">=</span> <span class="n">A2</span><span class="o">-</span><span class="n">Y</span>
    <span class="n">dW2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">dA1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ2</span><span class="p">)</span>
    <span class="n">dZ1</span> <span class="o">=</span> <span class="n">dA1</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">))</span>
    <span class="n">dW1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW2</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">b2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">W1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW1</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">b1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;loss: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 0 loss:  2.395166635058746
Epoch 10 loss:  0.2207416875926896
Epoch 20 loss:  0.16601548222727533
Epoch 30 loss:  0.13990677867922954
Epoch 40 loss:  0.12390102523919129
Epoch 50 loss:  0.11269161497108851
Epoch 60 loss:  0.10421329497723456
Epoch 70 loss:  0.09747959072905935
Epoch 80 loss:  0.09194898313097832
Epoch 90 loss:  0.0872943606401609
Final loss: 0.08367740628296327
</pre></div></div>
</div>
<p>To judge the newtork quality we do use again the confusion matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[118]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
<span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">A2</span><span class="o">&gt;.</span><span class="mi">5</span><span class="p">)[</span><span class="mi">0</span><span class="p">,:]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,:]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[8905  178]
 [ 115  802]]
              precision    recall  f1-score   support

       False       0.99      0.98      0.98      9083
        True       0.82      0.87      0.85       917

    accuracy                           0.97     10000
   macro avg       0.90      0.93      0.91     10000
weighted avg       0.97      0.97      0.97     10000

</pre></div></div>
</div>
</div>
<div class="section" id="Multiclass-Network">
<h2>Multiclass Network<a class="headerlink" href="#Multiclass-Network" title="Permalink to this headline">¶</a></h2>
<p>So far we did only classify if the number we feed to the network is just a 0 or not. We would like to recognize the different number now and therefore need a multiclass network. Each number is then a class and per class, we have multiple realizations of handwritten numbers. We therefore have to create an output layer, which is not only containing a single neuron, but 10 neurons. Each of these neuron can output a value between 0 and 1. Whenever the output is 1, the index of the neuron represents
the number predicted.</p>
<p>The output array</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>would therefore correspond to the value 1.</p>
<p>For this purpose, we need to reload the right labels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[120]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
<p>Then we’ll one-hot encode MNIST’s labels, to get a 10 x 70,000 array.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[121]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">digits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">examples</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">examples</span><span class="p">)</span>

<span class="n">Y_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">digits</span><span class="p">)[</span><span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)]</span>
<span class="n">Y_new</span> <span class="o">=</span> <span class="n">Y_new</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">digits</span><span class="p">,</span> <span class="n">examples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We also seperate into trainging and testing data</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[122]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">m</span> <span class="o">=</span> <span class="mi">60000</span>
<span class="n">m_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">m</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="n">m</span><span class="p">:]</span><span class="o">.</span><span class="n">T</span>
<span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_new</span><span class="p">[:,:</span><span class="n">m</span><span class="p">],</span> <span class="n">Y_new</span><span class="p">[:,</span><span class="n">m</span><span class="p">:]</span>

<span class="n">shuffle_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="n">shuffle_index</span><span class="p">],</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="n">shuffle_index</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[123]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">56</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">Y_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_77_0.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_77_0.png" style="width: 317px; height: 259px;" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[123]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])
</pre></div></div>
</div>
<div class="section" id="Changes-to-the-model">
<h3>Changes to the model<a class="headerlink" href="#Changes-to-the-model" title="Permalink to this headline">¶</a></h3>
<p>OK, so let’s consider what changes we need to make to the model itself.</p>
<div class="section" id="Forward-Pass">
<h4>Forward Pass<a class="headerlink" href="#Forward-Pass" title="Permalink to this headline">¶</a></h4>
<p>Only the last layer of our network is changing. To add the softmax, we have to replace our lone, final node with a 10 unit layer. Its final activations are the exponentials of its z-values, normalized across all ten such exponentials. So instead of just computing <span class="math notranslate nohighlight">\(\sigma(z)\)</span>, we compute the activation for each unit <span class="math notranslate nohighlight">\(i\)</span> using the softmax function: <span class="math">\begin{align*}
\sigma(z)_i = \frac{{\rm e}^{z_i}}{\sum_{j=0}^9{\rm e}^{z_i}}\ .
\end{align*}</span></p>
<p>So, in our vectorized code, the last line of forward propagation will be <code class="docutils literal notranslate"><span class="pre">A2</span> <span class="pre">=</span> <span class="pre">np.exp(Z2)</span> <span class="pre">/</span> <span class="pre">np.sum(np.exp(Z2),</span> <span class="pre">axis=0)</span></code>.</p>
</div>
<div class="section" id="id1">
<h4>Loss Function<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Our loss function now has to generalize to more than two classes. The general formula for <span class="math notranslate nohighlight">\(n\)</span> classes is: <span class="math">\begin{align*}
L(y,\hat{y}) = -\sum_{i=0}^n y_i\log(\hat{y}_i)\ .
\end{align*}</span> Averaging over <span class="math notranslate nohighlight">\(m\)</span> training examples this becomes: <span class="math">\begin{align*}
L(y,\hat{y}) = -\frac{1}{m}\sum_{j=0}^m\sum_{i=0}^n y_i^{(i)}\log(\hat{y}_i^{(i)})\ .
\end{align*}</span></p>
<p>So let’s define:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[124]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">compute_multiclass_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">):</span>
    <span class="n">L_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">)))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">L</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">L_sum</span>
    <span class="k">return</span> <span class="n">L</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Back-Propagation">
<h4>Back Propagation<a class="headerlink" href="#Back-Propagation" title="Permalink to this headline">¶</a></h4>
<p>Luckily it turns out that back propagation isn’t really affected by the switch to a softmax. A softmax generalizes the sigmoid activiation we’ve been using, and in such a way that the code we wrote earlier still works. We could verify this by deriving: <span class="math">\begin{align*}
\frac{\partial L}{\partial z_i} = \hat{y}_i - y_i\ .
\end{align*}</span></p>
<p>But we won’t walk through the steps here. Let’s just go ahead and build our final network.</p>
</div>
</div>
<div class="section" id="Build-and-Train">
<h3>Build and Train<a class="headerlink" href="#Build-and-Train" title="Permalink to this headline">¶</a></h3>
<p>As we have now more weights and classes, the training takes longer and we actually need also more episodes to achieve a good accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[164]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">n_x</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_h</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_h</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_h</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">digits</span><span class="p">,</span> <span class="n">n_h</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">digits</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y_train</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>

    <span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">A1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span><span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_multiclass_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">A2</span><span class="p">)</span>

    <span class="n">dZ2</span> <span class="o">=</span> <span class="n">A2</span><span class="o">-</span><span class="n">Y</span>
    <span class="n">dW2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">dA1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ2</span><span class="p">)</span>
    <span class="n">dZ1</span> <span class="o">=</span> <span class="n">dA1</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">))</span>
    <span class="n">dW1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW2</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">b2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">W1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW1</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">b1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;loss: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 0 loss:  6.754143565789832
Epoch 10 loss:  2.31326090354495
Epoch 20 loss:  1.6043877614303914
Epoch 30 loss:  1.2890004717094106
Epoch 40 loss:  1.1093197423471932
Epoch 50 loss:  0.9921173974283636
Epoch 60 loss:  0.908578404826914
Epoch 70 loss:  0.8453729163436552
Epoch 80 loss:  0.7955216748114543
Epoch 90 loss:  0.7549647468170931
Epoch 100 loss:  0.7211663466471266
Epoch 110 loss:  0.6924500602072033
Epoch 120 loss:  0.6676609441459171
Epoch 130 loss:  0.6459794129595765
Epoch 140 loss:  0.6268055274703503
Epoch 150 loss:  0.6096880566510727
Epoch 160 loss:  0.5942807158842909
Epoch 170 loss:  0.5803132060530969
Epoch 180 loss:  0.5675711192192956
Epoch 190 loss:  0.5558818101632366
Final loss: 0.5461445785100992
</pre></div></div>
</div>
<p>Let’s see how we did:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[234]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
<span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Model-performance">
<h4>Model performance<a class="headerlink" href="#Model-performance" title="Permalink to this headline">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[236]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[ 907    0   14    2    4   25   29   10   14   10]
 [   0 1102   16    6    2    7    5   17    4    7]
 [   9    6  850   33   13   19   27   30   37   17]
 [   6    6   24  816    7   62    4    5   54   22]
 [   2    0   15    7  824   22   30   19   21   75]
 [  32    2    8   62    8  666   22    4   51   11]
 [  18    4   28    7   21   28  829    3   23    5]
 [   3    0   24   16    3    9    1  857   16   39]
 [   3   14   42   51   21   48    8   12  736   14]
 [   0    1   11   10   79    6    3   71   18  809]]
              precision    recall  f1-score   support

           0       0.93      0.89      0.91      1015
           1       0.97      0.95      0.96      1166
           2       0.82      0.82      0.82      1041
           3       0.81      0.81      0.81      1006
           4       0.84      0.81      0.83      1015
           5       0.75      0.77      0.76       866
           6       0.87      0.86      0.86       966
           7       0.83      0.89      0.86       968
           8       0.76      0.78      0.77       949
           9       0.80      0.80      0.80      1008

    accuracy                           0.84     10000
   macro avg       0.84      0.84      0.84     10000
weighted avg       0.84      0.84      0.84     10000

</pre></div></div>
</div>
<p>We are at 84% accuray across all digits, which could be of course better. We may now plot image and the corresponding prediction.</p>
</div>
</div>
</div>
<div class="section" id="Test-the-model">
<h2>Test the model<a class="headerlink" href="#Test-the-model" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[237]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">i</span><span class="o">=</span><span class="mi">100</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[237]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
6
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_L13_1_deep_learning_95_1.png" class="no-scaled-link" src="../../_images/notebooks_L13_1_deep_learning_95_1.png" style="width: 258px; height: 255px;" />
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script></div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="2_deep_learning_keras.html" class="btn btn-neutral float-right" title="Neural Network with Keras" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../../lectures/L13/overview_13.html" class="btn btn-neutral float-left" title="Lecture Contents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Frank Cichos
      <span class="lastupdated">
        Last updated on Apr 06, 2021.
      </span>

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>